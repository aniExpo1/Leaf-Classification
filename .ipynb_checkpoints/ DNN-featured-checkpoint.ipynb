{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* one convolution notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow on 8889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/notebooks/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/notebooks/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! ls /home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.0.8-py2.py3-none-any.whl (276kB)\n",
      "\u001b[K    100% |################################| 276kB 2.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cython\n",
      "  Downloading Cython-0.26.1-cp27-cp27mu-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K    100% |################################| 2.9MB 450kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading PyYAML-3.12.tar.gz (253kB)\n",
      "\u001b[K    100% |################################| 256kB 5.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2c/f7/79/13f3a12cd723892437c0cfbde1230ab4d82947ff7b3839a4fc\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras, cython\n",
      "Successfully installed cython-0.26.1 keras-2.0.8 pyyaml-3.12\n"
     ]
    }
   ],
   "source": [
    "!pip install keras cython h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input,Convolution2D, Dense, Activation, Flatten, merge, Conv2D\n",
    "from keras.layers import MaxPooling2D, Dropout, LocallyConnected2D, MaxPool2D, MaxPool1D\n",
    "from keras.models import Model, load_model,  Sequential\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#from lib.data_split import load_train_data, load_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing / splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to organize the data\n",
    "def encode(train_df, test_df):\n",
    "    le = LabelEncoder().fit(train_df.species)\n",
    "    labels = le.transform(train_df.species)   #encode species strings\n",
    "    classes = list(le.classes_)\n",
    "    test_ids = test_df.id\n",
    "    \n",
    "    \n",
    "    train_df = train_df.drop([\"species\" , \"id\"] , axis = 1)\n",
    "    test_df =test_df.drop([\"id\"], axis =1)\n",
    "    \n",
    "    return train_df, labels, test_df, test_ids, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "0  0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
       "1  0.005859  0.000000  0.031250  0.015625  0.025391  0.001953  0.019531   \n",
       "2  0.005859  0.009766  0.019531  0.007812  0.003906  0.005859  0.068359   \n",
       "3  0.000000  0.003906  0.023438  0.005859  0.021484  0.019531  0.023438   \n",
       "4  0.005859  0.003906  0.048828  0.009766  0.013672  0.015625  0.005859   \n",
       "\n",
       "   margin8   margin9  margin10    ...      texture55  texture56  texture57  \\\n",
       "0      0.0  0.001953  0.033203    ...       0.007812   0.000000   0.002930   \n",
       "1      0.0  0.000000  0.007812    ...       0.000977   0.000000   0.000000   \n",
       "2      0.0  0.000000  0.044922    ...       0.154300   0.000000   0.005859   \n",
       "3      0.0  0.013672  0.017578    ...       0.000000   0.000977   0.000000   \n",
       "4      0.0  0.000000  0.005859    ...       0.096680   0.000000   0.021484   \n",
       "\n",
       "   texture58  texture59  texture60  texture61  texture62  texture63  texture64  \n",
       "0   0.002930   0.035156        0.0        0.0   0.004883   0.000000   0.025391  \n",
       "1   0.000977   0.023438        0.0        0.0   0.000977   0.039062   0.022461  \n",
       "2   0.000977   0.007812        0.0        0.0   0.000000   0.020508   0.002930  \n",
       "3   0.000000   0.020508        0.0        0.0   0.017578   0.000000   0.047852  \n",
       "4   0.000000   0.000000        0.0        0.0   0.000000   0.000000   0.031250  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, labels, test_df, test_ids, classes = encode(train_df, test_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(train_df)\n",
    "scaled_test_data = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df.values\n",
    "y = keras.utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits = 1,test_size = 0.2, random_state= 8)\n",
    "sss.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(X,y):\n",
    "    X_train, X_test = X[train_index],X[test_index]\n",
    "    y_train, y_test = y[train_index],y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 192)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 99)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The Dense Neural Network(DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the uotput layer the last layer should be the number of your classes.(here it's 99)\n",
    "# the input_shape should be like \n",
    "dnn_clf = Sequential([\n",
    "\n",
    "    Dense(100, input_shape=(192, 1), activation='relu'),\n",
    "    MaxPool1D(),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(.25),\n",
    "    Dense(99, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 192, 100)          200       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 96, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               960100    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 99)                9999      \n",
      "=================================================================\n",
      "Total params: 970,299\n",
      "Trainable params: 970,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_clf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile on (optimizer = Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_clf.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_train = X_train.reshape(-1, 192, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 192)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(792, 192, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding layers or depth might not help the scores any more.\n",
    "# but you can add random_forest and other classifiers prediction to the end of your data set that might help you\n",
    "# get a better score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 554 samples, validate on 238 samples\n",
      "Epoch 1/120\n",
      "554/554 [==============================] - 0s - loss: 4.5915 - acc: 0.0307 - val_loss: 4.5773 - val_acc: 0.0462\n",
      "Epoch 2/120\n",
      "554/554 [==============================] - 0s - loss: 4.5570 - acc: 0.0542 - val_loss: 4.5536 - val_acc: 0.0672\n",
      "Epoch 3/120\n",
      "554/554 [==============================] - 0s - loss: 4.5087 - acc: 0.0812 - val_loss: 4.5088 - val_acc: 0.1008\n",
      "Epoch 4/120\n",
      "554/554 [==============================] - 0s - loss: 4.4237 - acc: 0.0975 - val_loss: 4.4364 - val_acc: 0.1008\n",
      "Epoch 5/120\n",
      "554/554 [==============================] - 0s - loss: 4.2920 - acc: 0.1264 - val_loss: 4.3172 - val_acc: 0.1765\n",
      "Epoch 6/120\n",
      "554/554 [==============================] - 0s - loss: 4.1140 - acc: 0.1697 - val_loss: 4.1535 - val_acc: 0.1933\n",
      "Epoch 7/120\n",
      "554/554 [==============================] - 0s - loss: 3.8457 - acc: 0.2256 - val_loss: 3.9554 - val_acc: 0.1891\n",
      "Epoch 8/120\n",
      "554/554 [==============================] - 0s - loss: 3.5976 - acc: 0.2329 - val_loss: 3.6811 - val_acc: 0.2017\n",
      "Epoch 9/120\n",
      "554/554 [==============================] - 0s - loss: 3.2869 - acc: 0.2852 - val_loss: 3.4124 - val_acc: 0.2521\n",
      "Epoch 10/120\n",
      "554/554 [==============================] - 0s - loss: 2.9732 - acc: 0.3646 - val_loss: 3.1296 - val_acc: 0.3319\n",
      "Epoch 11/120\n",
      "554/554 [==============================] - 0s - loss: 2.6925 - acc: 0.4206 - val_loss: 2.8506 - val_acc: 0.3950\n",
      "Epoch 12/120\n",
      "554/554 [==============================] - 0s - loss: 2.4545 - acc: 0.4224 - val_loss: 2.6249 - val_acc: 0.4244\n",
      "Epoch 13/120\n",
      "554/554 [==============================] - 0s - loss: 2.2229 - acc: 0.4946 - val_loss: 2.4155 - val_acc: 0.4748\n",
      "Epoch 14/120\n",
      "554/554 [==============================] - 0s - loss: 2.0450 - acc: 0.5144 - val_loss: 2.2018 - val_acc: 0.5252\n",
      "Epoch 15/120\n",
      "554/554 [==============================] - 0s - loss: 1.8731 - acc: 0.5361 - val_loss: 2.0507 - val_acc: 0.5672\n",
      "Epoch 16/120\n",
      "554/554 [==============================] - 0s - loss: 1.7152 - acc: 0.5686 - val_loss: 1.8683 - val_acc: 0.6218\n",
      "Epoch 17/120\n",
      "554/554 [==============================] - 0s - loss: 1.5662 - acc: 0.6209 - val_loss: 1.8047 - val_acc: 0.6261\n",
      "Epoch 18/120\n",
      "554/554 [==============================] - 0s - loss: 1.5086 - acc: 0.6173 - val_loss: 1.7110 - val_acc: 0.6429\n",
      "Epoch 19/120\n",
      "554/554 [==============================] - 0s - loss: 1.3990 - acc: 0.6264 - val_loss: 1.5904 - val_acc: 0.6513\n",
      "Epoch 20/120\n",
      "554/554 [==============================] - 0s - loss: 1.3142 - acc: 0.6643 - val_loss: 1.5006 - val_acc: 0.6765\n",
      "Epoch 21/120\n",
      "554/554 [==============================] - 0s - loss: 1.1812 - acc: 0.6949 - val_loss: 1.4254 - val_acc: 0.6807\n",
      "Epoch 22/120\n",
      "554/554 [==============================] - 0s - loss: 1.1328 - acc: 0.7166 - val_loss: 1.3462 - val_acc: 0.6807\n",
      "Epoch 23/120\n",
      "554/554 [==============================] - 0s - loss: 1.0600 - acc: 0.7310 - val_loss: 1.2934 - val_acc: 0.7059\n",
      "Epoch 24/120\n",
      "554/554 [==============================] - 0s - loss: 1.0507 - acc: 0.7329 - val_loss: 1.2330 - val_acc: 0.6975\n",
      "Epoch 25/120\n",
      "554/554 [==============================] - 0s - loss: 0.9535 - acc: 0.7671 - val_loss: 1.1911 - val_acc: 0.6849\n",
      "Epoch 26/120\n",
      "554/554 [==============================] - 0s - loss: 0.8914 - acc: 0.7617 - val_loss: 1.1382 - val_acc: 0.7059\n",
      "Epoch 27/120\n",
      "554/554 [==============================] - 0s - loss: 0.8589 - acc: 0.8014 - val_loss: 1.1039 - val_acc: 0.7143\n",
      "Epoch 28/120\n",
      "554/554 [==============================] - 0s - loss: 0.7823 - acc: 0.7924 - val_loss: 1.0933 - val_acc: 0.7269\n",
      "Epoch 29/120\n",
      "554/554 [==============================] - 0s - loss: 0.7726 - acc: 0.8069 - val_loss: 1.0443 - val_acc: 0.7269\n",
      "Epoch 30/120\n",
      "554/554 [==============================] - 0s - loss: 0.7176 - acc: 0.8105 - val_loss: 1.0183 - val_acc: 0.7059\n",
      "Epoch 31/120\n",
      "554/554 [==============================] - 0s - loss: 0.6964 - acc: 0.8141 - val_loss: 0.9798 - val_acc: 0.7311\n",
      "Epoch 32/120\n",
      "554/554 [==============================] - 0s - loss: 0.6639 - acc: 0.8321 - val_loss: 0.9791 - val_acc: 0.7311\n",
      "Epoch 33/120\n",
      "554/554 [==============================] - 0s - loss: 0.6599 - acc: 0.8267 - val_loss: 0.9644 - val_acc: 0.7395\n",
      "Epoch 34/120\n",
      "554/554 [==============================] - 0s - loss: 0.5863 - acc: 0.8556 - val_loss: 0.9195 - val_acc: 0.7521\n",
      "Epoch 35/120\n",
      "554/554 [==============================] - 0s - loss: 0.5671 - acc: 0.8466 - val_loss: 0.8705 - val_acc: 0.7437\n",
      "Epoch 36/120\n",
      "554/554 [==============================] - 0s - loss: 0.5475 - acc: 0.8574 - val_loss: 0.8961 - val_acc: 0.7437\n",
      "Epoch 37/120\n",
      "554/554 [==============================] - 0s - loss: 0.5417 - acc: 0.8628 - val_loss: 0.8928 - val_acc: 0.7521\n",
      "Epoch 38/120\n",
      "554/554 [==============================] - 0s - loss: 0.4728 - acc: 0.8809 - val_loss: 0.8880 - val_acc: 0.7479\n",
      "Epoch 39/120\n",
      "554/554 [==============================] - 0s - loss: 0.4950 - acc: 0.8755 - val_loss: 0.8467 - val_acc: 0.7521\n",
      "Epoch 40/120\n",
      "554/554 [==============================] - 0s - loss: 0.4970 - acc: 0.8809 - val_loss: 0.8565 - val_acc: 0.7479\n",
      "Epoch 41/120\n",
      "554/554 [==============================] - 0s - loss: 0.4738 - acc: 0.8755 - val_loss: 0.8403 - val_acc: 0.7605\n",
      "Epoch 42/120\n",
      "554/554 [==============================] - 0s - loss: 0.4060 - acc: 0.9007 - val_loss: 0.8033 - val_acc: 0.7647\n",
      "Epoch 43/120\n",
      "554/554 [==============================] - 0s - loss: 0.4260 - acc: 0.8917 - val_loss: 0.7873 - val_acc: 0.7731\n",
      "Epoch 44/120\n",
      "554/554 [==============================] - 0s - loss: 0.3771 - acc: 0.9116 - val_loss: 0.7761 - val_acc: 0.7605\n",
      "Epoch 45/120\n",
      "554/554 [==============================] - 0s - loss: 0.3909 - acc: 0.9152 - val_loss: 0.7545 - val_acc: 0.7815\n",
      "Epoch 46/120\n",
      "554/554 [==============================] - 0s - loss: 0.3568 - acc: 0.9152 - val_loss: 0.7347 - val_acc: 0.7731\n",
      "Epoch 47/120\n",
      "554/554 [==============================] - 0s - loss: 0.3392 - acc: 0.9170 - val_loss: 0.7316 - val_acc: 0.7941\n",
      "Epoch 48/120\n",
      "554/554 [==============================] - 0s - loss: 0.3265 - acc: 0.9224 - val_loss: 0.7411 - val_acc: 0.7899\n",
      "Epoch 49/120\n",
      "554/554 [==============================] - 0s - loss: 0.3044 - acc: 0.9278 - val_loss: 0.7172 - val_acc: 0.7941\n",
      "Epoch 50/120\n",
      "554/554 [==============================] - 0s - loss: 0.3140 - acc: 0.9260 - val_loss: 0.7155 - val_acc: 0.7773\n",
      "Epoch 51/120\n",
      "554/554 [==============================] - 0s - loss: 0.3083 - acc: 0.9206 - val_loss: 0.7141 - val_acc: 0.7815\n",
      "Epoch 52/120\n",
      "554/554 [==============================] - 0s - loss: 0.2890 - acc: 0.9368 - val_loss: 0.7161 - val_acc: 0.7941\n",
      "Epoch 53/120\n",
      "554/554 [==============================] - 0s - loss: 0.3280 - acc: 0.9116 - val_loss: 0.7048 - val_acc: 0.7941\n",
      "Epoch 54/120\n",
      "554/554 [==============================] - 0s - loss: 0.2753 - acc: 0.9422 - val_loss: 0.6717 - val_acc: 0.8277\n",
      "Epoch 55/120\n",
      "554/554 [==============================] - 0s - loss: 0.2688 - acc: 0.9242 - val_loss: 0.6870 - val_acc: 0.7899\n",
      "Epoch 56/120\n",
      "554/554 [==============================] - 0s - loss: 0.2480 - acc: 0.9495 - val_loss: 0.7109 - val_acc: 0.7941\n",
      "Epoch 57/120\n",
      "554/554 [==============================] - 0s - loss: 0.2541 - acc: 0.9386 - val_loss: 0.6996 - val_acc: 0.8067\n",
      "Epoch 58/120\n",
      "554/554 [==============================] - 0s - loss: 0.2205 - acc: 0.9368 - val_loss: 0.6644 - val_acc: 0.8109\n",
      "Epoch 59/120\n",
      "554/554 [==============================] - 0s - loss: 0.1795 - acc: 0.9675 - val_loss: 0.6423 - val_acc: 0.7899\n",
      "Epoch 60/120\n",
      "554/554 [==============================] - 0s - loss: 0.2384 - acc: 0.9422 - val_loss: 0.6781 - val_acc: 0.8067\n",
      "Epoch 61/120\n",
      "554/554 [==============================] - 0s - loss: 0.2258 - acc: 0.9477 - val_loss: 0.6603 - val_acc: 0.8067\n",
      "Epoch 62/120\n",
      "554/554 [==============================] - 0s - loss: 0.2048 - acc: 0.9440 - val_loss: 0.6682 - val_acc: 0.8025\n",
      "Epoch 63/120\n",
      "554/554 [==============================] - 0s - loss: 0.2028 - acc: 0.9549 - val_loss: 0.6662 - val_acc: 0.8235\n",
      "Epoch 64/120\n",
      "554/554 [==============================] - 0s - loss: 0.1898 - acc: 0.9621 - val_loss: 0.6616 - val_acc: 0.8109\n",
      "Epoch 65/120\n",
      "554/554 [==============================] - 0s - loss: 0.1731 - acc: 0.9621 - val_loss: 0.6547 - val_acc: 0.8067\n",
      "Epoch 66/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554/554 [==============================] - 0s - loss: 0.2049 - acc: 0.9440 - val_loss: 0.6730 - val_acc: 0.7983\n",
      "Epoch 67/120\n",
      "554/554 [==============================] - 0s - loss: 0.1675 - acc: 0.9657 - val_loss: 0.6591 - val_acc: 0.8067\n",
      "Epoch 68/120\n",
      "554/554 [==============================] - 0s - loss: 0.1882 - acc: 0.9458 - val_loss: 0.6371 - val_acc: 0.8109\n",
      "Epoch 69/120\n",
      "554/554 [==============================] - 0s - loss: 0.1776 - acc: 0.9585 - val_loss: 0.6326 - val_acc: 0.8193\n",
      "Epoch 70/120\n",
      "554/554 [==============================] - 0s - loss: 0.1757 - acc: 0.9531 - val_loss: 0.6502 - val_acc: 0.7815\n",
      "Epoch 71/120\n",
      "554/554 [==============================] - 0s - loss: 0.1673 - acc: 0.9531 - val_loss: 0.6592 - val_acc: 0.8067\n",
      "Epoch 72/120\n",
      "554/554 [==============================] - 0s - loss: 0.1491 - acc: 0.9675 - val_loss: 0.6504 - val_acc: 0.8109\n",
      "Epoch 73/120\n",
      "554/554 [==============================] - 0s - loss: 0.1490 - acc: 0.9657 - val_loss: 0.6560 - val_acc: 0.8109\n",
      "Epoch 74/120\n",
      "554/554 [==============================] - 0s - loss: 0.1567 - acc: 0.9711 - val_loss: 0.6275 - val_acc: 0.8067\n",
      "Epoch 75/120\n",
      "554/554 [==============================] - 0s - loss: 0.1617 - acc: 0.9567 - val_loss: 0.6099 - val_acc: 0.8193\n",
      "Epoch 76/120\n",
      "554/554 [==============================] - 0s - loss: 0.1510 - acc: 0.9729 - val_loss: 0.5834 - val_acc: 0.8361\n",
      "Epoch 77/120\n",
      "554/554 [==============================] - 0s - loss: 0.1412 - acc: 0.9783 - val_loss: 0.5994 - val_acc: 0.8109\n",
      "Epoch 78/120\n",
      "554/554 [==============================] - 0s - loss: 0.1224 - acc: 0.9783 - val_loss: 0.6031 - val_acc: 0.8151\n",
      "Epoch 79/120\n",
      "554/554 [==============================] - 0s - loss: 0.1340 - acc: 0.9711 - val_loss: 0.6288 - val_acc: 0.8067\n",
      "Epoch 80/120\n",
      "554/554 [==============================] - 0s - loss: 0.1064 - acc: 0.9838 - val_loss: 0.6205 - val_acc: 0.8193\n",
      "Epoch 81/120\n",
      "554/554 [==============================] - 0s - loss: 0.1497 - acc: 0.9603 - val_loss: 0.6134 - val_acc: 0.8277\n",
      "Epoch 82/120\n",
      "554/554 [==============================] - 0s - loss: 0.1352 - acc: 0.9693 - val_loss: 0.6110 - val_acc: 0.8193\n",
      "Epoch 83/120\n",
      "554/554 [==============================] - 0s - loss: 0.1001 - acc: 0.9838 - val_loss: 0.5925 - val_acc: 0.8193\n",
      "Epoch 84/120\n",
      "554/554 [==============================] - 0s - loss: 0.1023 - acc: 0.9801 - val_loss: 0.6041 - val_acc: 0.8193\n",
      "Epoch 85/120\n",
      "554/554 [==============================] - 0s - loss: 0.1133 - acc: 0.9783 - val_loss: 0.6216 - val_acc: 0.8235\n",
      "Epoch 86/120\n",
      "554/554 [==============================] - 0s - loss: 0.1038 - acc: 0.9838 - val_loss: 0.6096 - val_acc: 0.8235\n",
      "Epoch 87/120\n",
      "554/554 [==============================] - 0s - loss: 0.1102 - acc: 0.9783 - val_loss: 0.6245 - val_acc: 0.8193\n",
      "Epoch 88/120\n",
      "554/554 [==============================] - 0s - loss: 0.1038 - acc: 0.9747 - val_loss: 0.6118 - val_acc: 0.8277\n",
      "Epoch 89/120\n",
      "554/554 [==============================] - 0s - loss: 0.1058 - acc: 0.9783 - val_loss: 0.6203 - val_acc: 0.8067\n",
      "Epoch 90/120\n",
      "554/554 [==============================] - 0s - loss: 0.1185 - acc: 0.9729 - val_loss: 0.6188 - val_acc: 0.8151\n",
      "Epoch 91/120\n",
      "554/554 [==============================] - 0s - loss: 0.1079 - acc: 0.9765 - val_loss: 0.5988 - val_acc: 0.8235\n",
      "Epoch 92/120\n",
      "554/554 [==============================] - 0s - loss: 0.0918 - acc: 0.9765 - val_loss: 0.6087 - val_acc: 0.8277\n",
      "Epoch 93/120\n",
      "554/554 [==============================] - 0s - loss: 0.1068 - acc: 0.9729 - val_loss: 0.6210 - val_acc: 0.8151\n",
      "Epoch 94/120\n",
      "554/554 [==============================] - 0s - loss: 0.1045 - acc: 0.9801 - val_loss: 0.6160 - val_acc: 0.8151\n",
      "Epoch 95/120\n",
      "554/554 [==============================] - 0s - loss: 0.0823 - acc: 0.9838 - val_loss: 0.5774 - val_acc: 0.8361\n",
      "Epoch 96/120\n",
      "554/554 [==============================] - 0s - loss: 0.0777 - acc: 0.9892 - val_loss: 0.5778 - val_acc: 0.8193\n",
      "Epoch 97/120\n",
      "554/554 [==============================] - 0s - loss: 0.0785 - acc: 0.9856 - val_loss: 0.5719 - val_acc: 0.8319\n",
      "Epoch 98/120\n",
      "554/554 [==============================] - 0s - loss: 0.0776 - acc: 0.9856 - val_loss: 0.5952 - val_acc: 0.8235\n",
      "Epoch 99/120\n",
      "554/554 [==============================] - 0s - loss: 0.0944 - acc: 0.9765 - val_loss: 0.6069 - val_acc: 0.8025\n",
      "Epoch 100/120\n",
      "554/554 [==============================] - 0s - loss: 0.0770 - acc: 0.9856 - val_loss: 0.6022 - val_acc: 0.8067\n",
      "Epoch 101/120\n",
      "554/554 [==============================] - 0s - loss: 0.0735 - acc: 0.9838 - val_loss: 0.5846 - val_acc: 0.8361\n",
      "Epoch 102/120\n",
      "554/554 [==============================] - 0s - loss: 0.0973 - acc: 0.9765 - val_loss: 0.5895 - val_acc: 0.8193\n",
      "Epoch 103/120\n",
      "554/554 [==============================] - 0s - loss: 0.0855 - acc: 0.9783 - val_loss: 0.5739 - val_acc: 0.8235\n",
      "Epoch 104/120\n",
      "554/554 [==============================] - 0s - loss: 0.0742 - acc: 0.9874 - val_loss: 0.5856 - val_acc: 0.8235\n",
      "Epoch 105/120\n",
      "554/554 [==============================] - 0s - loss: 0.0806 - acc: 0.9856 - val_loss: 0.6117 - val_acc: 0.8361\n",
      "Epoch 106/120\n",
      "554/554 [==============================] - 0s - loss: 0.0665 - acc: 0.9856 - val_loss: 0.6212 - val_acc: 0.8151\n",
      "Epoch 107/120\n",
      "554/554 [==============================] - 0s - loss: 0.0697 - acc: 0.9856 - val_loss: 0.6088 - val_acc: 0.8235\n",
      "Epoch 108/120\n",
      "554/554 [==============================] - 0s - loss: 0.0751 - acc: 0.9801 - val_loss: 0.5907 - val_acc: 0.8193\n",
      "Epoch 109/120\n",
      "554/554 [==============================] - 0s - loss: 0.0659 - acc: 0.9838 - val_loss: 0.5723 - val_acc: 0.8319\n",
      "Epoch 110/120\n",
      "554/554 [==============================] - 0s - loss: 0.0705 - acc: 0.9892 - val_loss: 0.5593 - val_acc: 0.8319\n",
      "Epoch 111/120\n",
      "554/554 [==============================] - 0s - loss: 0.0798 - acc: 0.9801 - val_loss: 0.5559 - val_acc: 0.8403\n",
      "Epoch 112/120\n",
      "554/554 [==============================] - 0s - loss: 0.0490 - acc: 0.9964 - val_loss: 0.5568 - val_acc: 0.8487\n",
      "Epoch 113/120\n",
      "554/554 [==============================] - 0s - loss: 0.0755 - acc: 0.9819 - val_loss: 0.5730 - val_acc: 0.8193\n",
      "Epoch 114/120\n",
      "554/554 [==============================] - 0s - loss: 0.0598 - acc: 0.9874 - val_loss: 0.5643 - val_acc: 0.8445\n",
      "Epoch 115/120\n",
      "554/554 [==============================] - 0s - loss: 0.0607 - acc: 0.9819 - val_loss: 0.5772 - val_acc: 0.8277\n",
      "Epoch 116/120\n",
      "554/554 [==============================] - 0s - loss: 0.0497 - acc: 0.9964 - val_loss: 0.6090 - val_acc: 0.8277\n",
      "Epoch 117/120\n",
      "554/554 [==============================] - 0s - loss: 0.0601 - acc: 0.9910 - val_loss: 0.5990 - val_acc: 0.8319\n",
      "Epoch 118/120\n",
      "554/554 [==============================] - 0s - loss: 0.0587 - acc: 0.9892 - val_loss: 0.5992 - val_acc: 0.8319\n",
      "Epoch 119/120\n",
      "554/554 [==============================] - 0s - loss: 0.0507 - acc: 0.9910 - val_loss: 0.5934 - val_acc: 0.8319\n",
      "Epoch 120/120\n",
      "554/554 [==============================] - 0s - loss: 0.0685 - acc: 0.9801 - val_loss: 0.5924 - val_acc: 0.8445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6906de5b50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf.fit(X2_train,y_train, validation_split=.3, epochs=120)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_test = X_test.reshape(-1, 192, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "y_preds = dnn_clf.predict_classes(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 44, 32, 36, 61, 62, 17, 55, 58, 75,  2, 78, 84, 48, 28, 93, 59,\n",
       "       74,  9, 10, 16, 25, 65, 11, 65, 39, 98, 64,  7, 66, 62, 93, 96, 14,\n",
       "       47, 94, 35,  5, 22, 72, 51, 49, 74, 48, 89, 98, 21,  5, 56, 64, 82,\n",
       "       76, 86, 88, 57, 37, 95, 18, 39, 26, 13, 85, 83, 46,  8, 42,  4, 30,\n",
       "       20, 81, 86, 11, 63, 16, 95, 53,  4, 45, 48, 66, 60, 43, 25, 15, 47,\n",
       "       37, 50, 86, 23, 10, 97, 17, 96, 45, 33, 68, 30, 10, 94,  2, 67, 14,\n",
       "       42, 27, 89, 52, 73, 41, 54, 22, 92, 77, 87, 34, 79, 85,  3, 41, 81,\n",
       "       49, 21, 91, 82, 45, 41, 61, 84, 51, 88, 86, 29, 78,  9, 83,  1, 10,\n",
       "       54, 73, 29, 69, 35, 71, 72, 44, 19, 76, 57, 90, 43, 43, 23, 29, 15,\n",
       "       80,  6, 19, 97, 23, 87, 68, 47, 43,  7, 75,  0, 50, 97, 60, 91, 33,\n",
       "       79, 56, 58, 32, 37, 67, 53,  6, 60, 40, 40, 53, 80, 63, 28, 27,  0,\n",
       "       71, 20, 90, 70, 34, 13, 46, 77,  8, 59, 83])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 44, 32, 36, 61, 62, 17, 55, 58, 75,  2, 78, 84, 41, 28, 93, 59,\n",
       "       74,  9, 92, 16, 25, 65, 11, 65, 39, 98, 64,  7, 66, 62, 93, 96, 14,\n",
       "       47, 94, 35,  5, 22, 72, 51, 49, 74, 48, 89, 98, 21,  5, 56, 64, 82,\n",
       "       76, 69, 88, 57, 38, 95, 18, 39, 26, 13, 85, 83, 46,  8, 42,  4, 30,\n",
       "       20, 81, 26, 11, 63, 16, 95, 53,  4, 45, 48, 66, 60, 43, 25, 15, 19,\n",
       "       37, 50, 86, 70, 31, 97, 17, 96, 31, 33, 68, 30, 10, 94,  2, 67, 14,\n",
       "       42, 27, 89, 52, 73, 12, 54, 22, 92, 77, 87, 34, 79, 85,  3, 12, 81,\n",
       "       49, 21, 91, 82, 45, 41, 61, 84, 51, 88, 86, 29, 78,  9, 83,  1, 10,\n",
       "       54, 73, 38, 69, 35, 71, 72, 44, 19, 76, 57, 90, 24, 24, 23, 29, 15,\n",
       "       80,  6,  1, 18, 23, 87, 68, 47, 43,  7, 75,  0, 50, 97, 52, 91, 33,\n",
       "       79, 56, 58, 32, 37, 67, 53,  6, 60, 40, 40, 55, 80, 63, 28, 27,  0,\n",
       "       71, 20, 90, 70, 34, 13, 46, 77,  8, 59,  3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True, False, False,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test == y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y_test   ===>   to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/198 [=======================>......] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#Scalar test loss \n",
    "loss , accuracy = dnn_clf.evaluate(X2_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40004540106864889"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90404040343833691"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#turn your y_test back to argmax for confusion matrix results.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 2, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 2, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 2, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 2]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
